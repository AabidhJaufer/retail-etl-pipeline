{"timestamp":"2026-02-09T12:56:14.182885Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-02-09T12:56:14.183643Z","level":"info","event":"Filling up the DagBag from /home/aabidh/retail_pipeline/airflow/dags/retail_dag.py","logger":"airflow.models.dagbag.BundleDagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-02-09T12:56:14.191247Z","level":"warning","event":"The `airflow.operators.bash.BashOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.bash.BashOperator'`.","category":"DeprecatedImportWarning","filename":"/home/aabidh/retail_pipeline/airflow/dags/retail_dag.py","lineno":2,"logger":"py.warnings"}
{"timestamp":"2026-02-09T12:56:14.210084Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:14.210213Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:14.210386Z","level":"info","event":"Current task name:transform","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:14.210435Z","level":"info","event":"Dag name:retail_pipeline_dag","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:14.210836Z","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":78}
{"timestamp":"2026-02-09T12:56:14.211889Z","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'python3 ~/retail_pipeline/scripts/transform.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":80}
{"timestamp":"2026-02-09T12:56:14.212778Z","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":92}
{"timestamp":"2026-02-09T12:56:14.892840Z","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:15.895050Z","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:15.921175Z","level":"info","event":"26/02/09 20:56:15 WARN Utils: Your hostname, DESKTOP-3RNPGOP, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:15.925152Z","level":"info","event":"26/02/09 20:56:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:16.326848Z","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:16.327476Z","level":"info","event":"Setting default log level to \"WARN\".","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:16.327578Z","level":"info","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:16.796564Z","level":"info","event":"26/02/09 20:56:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:17.532321Z","level":"info","event":"26/02/09 20:56:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.839657Z","level":"info","event":"\r[Stage 0:===========================================================(1 + 0) / 1]\r\r                                                                                \r\r[Stage 1:>                                                          (0 + 1) / 1]\r\r                                                                                \r26/02/09 20:56:23 ERROR FileFormatWriter: Aborting job 814525f6-bf0f-4e56-8446-33589cb188c5.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.839809Z","level":"info","event":"java.io.FileNotFoundException: File file:/home/aabidh/retail_pipeline/data/processed/dim_product/_temporary/0/task_202602092056237100230517795847331_0001_m_000000 does not exist","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.839859Z","level":"info","event":"\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:798)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.839894Z","level":"info","event":"\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2078)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.839922Z","level":"info","event":"\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2122)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.839946Z","level":"info","event":"\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:1020)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.839969Z","level":"info","event":"\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:488)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.839992Z","level":"info","event":"\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:405)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840017Z","level":"info","event":"\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840041Z","level":"info","event":"\tat org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840063Z","level":"info","event":"\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840086Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840107Z","level":"info","event":"\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840129Z","level":"info","event":"\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:496)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840151Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840172Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840193Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840214Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840235Z","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840255Z","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840275Z","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840295Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:185)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840315Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:177)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840336Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:285)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840357Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:139)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840378Z","level":"info","event":"\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840398Z","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840417Z","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840532Z","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840569Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:139)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840598Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:308)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840622Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:138)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840647Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840698Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:92)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840746Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:250)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840807Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:185)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840851Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:717)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840879Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840905Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:201)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840930Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:194)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840960Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:491)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.840984Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:107)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841008Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:491)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841038Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841074Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:360)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841139Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:356)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841184Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841242Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841273Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:467)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841300Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:194)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841324Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:155)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841346Z","level":"info","event":"\tat scala.util.Try$.apply(Try.scala:217)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841368Z","level":"info","event":"\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1392)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841391Z","level":"info","event":"\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841413Z","level":"info","event":"\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841435Z","level":"info","event":"\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841456Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:160)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841478Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:239)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841502Z","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:592)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841536Z","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:115)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841559Z","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:369)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841581Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841602Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841622Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841672Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841712Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841775Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841818Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841845Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841869Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841892Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841916Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.841938Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:1583)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.922467Z","level":"info","event":"--- Starting Transformation ---","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.922607Z","level":"info","event":"Traceback (most recent call last):","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.922658Z","level":"info","event":"  File \"/home/aabidh/retail_pipeline/scripts/transform.py\", line 23, in <module>","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.922694Z","level":"info","event":"    ).write.mode(\"overwrite\").parquet(os.path.join(PROC_DIR, \"dim_product\"))","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.922721Z","level":"info","event":"                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.922745Z","level":"info","event":"  File \"/home/aabidh/retail_pipeline/venv/lib/python3.12/site-packages/pyspark/sql/readwriter.py\", line 2003, in parquet","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.932393Z","level":"info","event":"    self._jwrite.parquet(path)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.932625Z","level":"info","event":"  File \"/home/aabidh/retail_pipeline/venv/lib/python3.12/site-packages/py4j/java_gateway.py\", line 1362, in __call__","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.934154Z","level":"info","event":"    return_value = get_return_value(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.934269Z","level":"info","event":"                   ^^^^^^^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.934328Z","level":"info","event":"  File \"/home/aabidh/retail_pipeline/venv/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py\", line 263, in deco","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.934741Z","level":"info","event":"    return f(*a, **kw)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.934847Z","level":"info","event":"           ^^^^^^^^^^^","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.934903Z","level":"info","event":"  File \"/home/aabidh/retail_pipeline/venv/lib/python3.12/site-packages/py4j/protocol.py\", line 327, in get_return_value","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.935197Z","level":"info","event":"    raise Py4JJavaError(","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.976819Z","level":"info","event":"py4j.protocol.Py4JJavaError: An error occurred while calling o55.parquet.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.976962Z","level":"info","event":": java.io.FileNotFoundException: File file:/home/aabidh/retail_pipeline/data/processed/dim_product/_temporary/0/task_202602092056237100230517795847331_0001_m_000000 does not exist","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977011Z","level":"info","event":"\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:798)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977046Z","level":"info","event":"\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2078)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977075Z","level":"info","event":"\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2122)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977101Z","level":"info","event":"\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:1020)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977126Z","level":"info","event":"\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:488)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977151Z","level":"info","event":"\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:405)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977175Z","level":"info","event":"\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977197Z","level":"info","event":"\tat org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977218Z","level":"info","event":"\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977240Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977261Z","level":"info","event":"\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977282Z","level":"info","event":"\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:496)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977303Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977324Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977345Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977367Z","level":"info","event":"\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977389Z","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977410Z","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977431Z","level":"info","event":"\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977450Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:185)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977502Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:177)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977542Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:285)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977571Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:139)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977596Z","level":"info","event":"\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977619Z","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977641Z","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977662Z","level":"info","event":"\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977683Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:139)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977705Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:308)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977726Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:138)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977747Z","level":"info","event":"\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977767Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:92)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977788Z","level":"info","event":"\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:250)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977810Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:185)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977830Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:717)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.977930Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978032Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:201)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978075Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:194)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978109Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:491)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978136Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:107)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978160Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:491)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978182Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978204Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:360)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978225Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:356)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978246Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978267Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978288Z","level":"info","event":"\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:467)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978309Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:194)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978330Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:155)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978351Z","level":"info","event":"\tat scala.util.Try$.apply(Try.scala:217)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978372Z","level":"info","event":"\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1392)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978392Z","level":"info","event":"\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1453)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978413Z","level":"info","event":"\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:58)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978432Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:160)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978452Z","level":"info","event":"\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:239)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978472Z","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameWriter.runCommand(DataFrameWriter.scala:592)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978533Z","level":"info","event":"\tat org.apache.spark.sql.classic.DataFrameWriter.save(DataFrameWriter.scala:115)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978563Z","level":"info","event":"\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:369)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978614Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978651Z","level":"info","event":"\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:75)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978676Z","level":"info","event":"\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978699Z","level":"info","event":"\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978722Z","level":"info","event":"\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978744Z","level":"info","event":"\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978765Z","level":"info","event":"\tat py4j.Gateway.invoke(Gateway.java:282)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978787Z","level":"info","event":"\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978808Z","level":"info","event":"\tat py4j.commands.CallCommand.execute(CallCommand.java:79)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978829Z","level":"info","event":"\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978851Z","level":"info","event":"\tat py4j.ClientServerConnection.run(ClientServerConnection.java:108)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978872Z","level":"info","event":"\tat java.base/java.lang.Thread.run(Thread.java:1583)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978893Z","level":"info","event":"\tSuppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.978915Z","level":"info","event":"\t\tat org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:798)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979000Z","level":"info","event":"\t\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2078)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979098Z","level":"info","event":"\t\tat org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2122)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979279Z","level":"info","event":"\t\tat org.apache.hadoop.fs.ChecksumFileSystem.listStatus(ChecksumFileSystem.java:1020)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979381Z","level":"info","event":"\t\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:488)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979423Z","level":"info","event":"\t\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:405)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979517Z","level":"info","event":"\t\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979611Z","level":"info","event":"\t\tat org.apache.parquet.hadoop.ParquetOutputCommitter.commitJob(ParquetOutputCommitter.java:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979870Z","level":"info","event":"\t\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979940Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$writeAndCommit$3(FileFormatWriter.scala:275)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.979985Z","level":"info","event":"\t\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980046Z","level":"info","event":"\t\tat org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:496)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980178Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:275)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980254Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:306)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980571Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:189)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980633Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:195)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980680Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:117)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980722Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:115)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980761Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:129)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980798Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:185)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980835Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:177)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980878Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:285)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980919Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:139)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980956Z","level":"info","event":"\t\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.980998Z","level":"info","event":"\t\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981046Z","level":"info","event":"\t\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:106)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981096Z","level":"info","event":"\t\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981144Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:139)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981189Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:308)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981236Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:138)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981283Z","level":"info","event":"\t\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981332Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:92)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981375Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:250)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981417Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:185)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981463Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:717)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981564Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:184)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981610Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:201)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981649Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$3.applyOrElse(QueryExecution.scala:194)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981686Z","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:491)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981733Z","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:107)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981790Z","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:491)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981836Z","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981876Z","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:360)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981911Z","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:356)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.981960Z","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982012Z","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:37)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982059Z","level":"info","event":"\t\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:467)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982128Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:194)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982178Z","level":"info","event":"\t\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:155)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982206Z","level":"info","event":"\t\tat scala.util.Try$.apply(Try.scala:217)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982231Z","level":"info","event":"\t\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1392)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982255Z","level":"info","event":"\t\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982277Z","level":"info","event":"\t\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982299Z","level":"info","event":"\t\t... 18 more","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:23.982334Z","level":"info","event":"","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:24.573016Z","level":"info","event":"Command exited with return code 1","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":103}
{"timestamp":"2026-02-09T12:56:24.573519Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":1120,"error_detail":[{"exc_type":"AirflowException","exc_value":"Bash command failed. The command returned a non-zero exit code 1.","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/aabidh/retail_pipeline/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1068,"name":"run"},{"filename":"/home/aabidh/retail_pipeline/venv/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1477,"name":"_execute_task"},{"filename":"/home/aabidh/retail_pipeline/venv/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":417,"name":"wrapper"},{"filename":"/home/aabidh/retail_pipeline/venv/lib/python3.12/site-packages/airflow/providers/standard/operators/bash.py","lineno":227,"name":"execute"}],"is_group":false,"exceptions":[]}]}
{"timestamp":"2026-02-09T12:56:24.591224Z","level":"info","event":"Task instance in failure state","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:24.591507Z","level":"info","event":"Task start","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:24.591612Z","level":"info","event":"Task:<Task(BashOperator): transform>","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:24.591656Z","level":"info","event":"Failure caused by Bash command failed. The command returned a non-zero exit code 1.","logger":"task.stdout"}
