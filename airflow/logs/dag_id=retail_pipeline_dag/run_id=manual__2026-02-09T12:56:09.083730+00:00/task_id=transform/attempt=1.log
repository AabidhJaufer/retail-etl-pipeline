{"timestamp":"2026-02-09T12:56:14.173219Z","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2026-02-09T12:56:14.173854Z","level":"info","event":"Filling up the DagBag from /home/aabidh/retail_pipeline/airflow/dags/retail_dag.py","logger":"airflow.models.dagbag.BundleDagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2026-02-09T12:56:14.181702Z","level":"warning","event":"The `airflow.operators.bash.BashOperator` attribute is deprecated. Please use `'airflow.providers.standard.operators.bash.BashOperator'`.","category":"DeprecatedImportWarning","filename":"/home/aabidh/retail_pipeline/airflow/dags/retail_dag.py","lineno":2,"logger":"py.warnings"}
{"timestamp":"2026-02-09T12:56:14.203270Z","level":"info","event":"Task instance is in running state","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:14.203391Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:14.203542Z","level":"info","event":"Current task name:transform","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:14.203610Z","level":"info","event":"Dag name:retail_pipeline_dag","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:14.203959Z","level":"info","event":"Tmp dir root location: /tmp","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":78}
{"timestamp":"2026-02-09T12:56:14.205061Z","level":"info","event":"Running command: ['/usr/bin/bash', '-c', 'python3 ~/retail_pipeline/scripts/transform.py']","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":80}
{"timestamp":"2026-02-09T12:56:14.206132Z","level":"info","event":"Output:","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":92}
{"timestamp":"2026-02-09T12:56:14.892869Z","level":"info","event":"WARNING: Using incubator modules: jdk.incubator.vector","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:15.893307Z","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:15.920004Z","level":"info","event":"26/02/09 20:56:15 WARN Utils: Your hostname, DESKTOP-3RNPGOP, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:15.924196Z","level":"info","event":"26/02/09 20:56:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:16.323672Z","level":"info","event":"Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:16.324127Z","level":"info","event":"Setting default log level to \"WARN\".","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:16.324229Z","level":"info","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:16.810301Z","level":"info","event":"26/02/09 20:56:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:25.044074Z","level":"info","event":"\r[Stage 1:>                                                          (0 + 1) / 1]\r\r                                                                                \r--- Starting Transformation ---","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:25.044242Z","level":"info","event":"✅ dim_product created.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:25.044304Z","level":"info","event":"✅ dim_customer created.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:25.044347Z","level":"info","event":"✅ fact_sales created.","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":99}
{"timestamp":"2026-02-09T12:56:25.636970Z","level":"info","event":"Command exited with return code 0","logger":"airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook","filename":"subprocess.py","lineno":103}
{"timestamp":"2026-02-09T12:56:25.637459Z","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('019c4279-42ae-7ce0-bbbd-818343a934a5'), task_id='transform', dag_id='retail_pipeline_dag', run_id='manual__2026-02-09T12:56:09.083730+00:00', try_number=1, dag_version_id=UUID('019c4278-06cc-776b-ac84-b135b1cc04f1'), map_index=-1, hostname='DESKTOP-3RNPGOP.localdomain', context_carrier={}, task=<Task(BashOperator): transform>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2026, 2, 9, 12, 56, 14, 150721, tzinfo=datetime.timezone.utc), end_date=None, state=<TaskInstanceState.RUNNING: 'running'>, is_mapped=False, rendered_map_index=None)","logger":"task","filename":"task_runner.py","lineno":1522}
{"timestamp":"2026-02-09T12:56:25.658682Z","level":"info","event":"Task instance in success state","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:25.658794Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","logger":"task.stdout"}
{"timestamp":"2026-02-09T12:56:25.658982Z","level":"info","event":"Task operator:<Task(BashOperator): transform>","logger":"task.stdout"}
